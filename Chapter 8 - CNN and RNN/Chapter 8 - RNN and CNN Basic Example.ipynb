{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Deep Learning - a use case based approach to understand deep neural networks\n",
    "\n",
    "### Umberto Michelucci\n",
    "\n",
    "Buy the book: https://www.apress.com/us/book/9781484237892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Umberto Michelucci 2018-2019 - umberto.michelucci@gmail.com \n",
    "\n",
    "github repository: https://github.com/michelucci/applieddeeplearningbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000',\n",
       " '0001',\n",
       " '0010',\n",
       " '0011',\n",
       " '0100',\n",
       " '0101',\n",
       " '0110',\n",
       " '0111',\n",
       " '1000',\n",
       " '1001',\n",
       " '1010',\n",
       " '1011',\n",
       " '1100',\n",
       " '1101',\n",
       " '1110',\n",
       " '1111']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ['{0:04b}'.format(i) for i in range(2**4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 15\n",
    "ll = 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = ['{0:015b}'.format(i) for i in range(ll)]\n",
    "shuffle(train_input)\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append([j])\n",
    "    ti.append(np.array(temp_list))\n",
    "train_input = ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 15, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = []\n",
    " \n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*(nn+1))\n",
    "    temp_list[count]=1\n",
    "    train_output.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_output).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = ll-2000\n",
    "test_input = train_input[NUM_EXAMPLES:]\n",
    "test_output = train_output[NUM_EXAMPLES:] #everything beyond 10,000\n",
    " \n",
    "train_input = train_input[:NUM_EXAMPLES]\n",
    "train_output = train_output[:NUM_EXAMPLES] #till 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 15, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30768, 15, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, nn,1])\n",
    "target = tf.placeholder(tf.float32, [None, (nn+1)])\n",
    "\n",
    "num_hidden = 24\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden,state_is_tuple=True)\n",
    "\n",
    "val, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\n",
    "val = tf.transpose(val, [1, 0, 2])\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(target * tf.log(tf.clip_by_value(prediction,1e-10,1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umber\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 error 79.1%\n",
      "Epoch 10 error 33.3%\n",
      "Epoch 20 error 9.4%\n",
      "Epoch 30 error 4.1%\n",
      "Epoch 40 error 2.5%\n",
      "Epoch 50 error 1.6%\n",
      "Epoch 60 error 1.7%\n",
      "Epoch 70 error 1.6%\n",
      "Epoch 80 error 1.3%\n",
      "Epoch 90 error 0.7%\n",
      "Epoch 100 error 0.5%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "no_of_batches = int(len(train_input)/batch_size)\n",
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "        ptr+=batch_size\n",
    "        sess.run(minimize,{data: inp, target: out})\n",
    "    if (i % 10 == 0):\n",
    "        #print (\"Epoch - \",str(i))\n",
    "        incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "        print('Epoch {:2d} error {:3.1f}%'.format(i , 100 * incorrect))\n",
    "incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sess.run(model.prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0],[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 20\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Number of neurons in the layers\n",
    "n1 = 15 # Number of neurons in layer 1\n",
    "n2 = 21 # Number of neurons in output layer \n",
    "\n",
    "cost_history = np.empty(shape=[1], dtype = float)\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "X = tf.placeholder(tf.float32, [20, None])\n",
    "Y = tf.placeholder(tf.float32, [21, None])\n",
    "W1 = tf.Variable(tf.truncated_normal([n1, n_dim], stddev=.1)) \n",
    "b1 = tf.Variable(tf.constant(0.1, shape = [n1,1]) )\n",
    "W2 = tf.Variable(tf.truncated_normal([n2, n1], stddev=.1)) \n",
    "b2 = tf.Variable(tf.constant(0.1, shape = [n2,1])) \n",
    "                 \n",
    "# Let's build our network...\n",
    "Z1 = tf.nn.relu(tf.matmul(W1, X) + b1) # n1 x n_dim * n_dim x n_obs = n1 x n_obs\n",
    "Z2 = tf.matmul(W2, Z1) + b2 # n2 x n1 * n1 * n_obs = n2 x n_obs\n",
    "y_ = tf.nn.softmax(Z2,0) # n2 x n_obs (10 x None)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(y_)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "mistakes = tf.not_equal(tf.argmax(Y, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 95000\n",
    "test_size = 5000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 100\n",
    "    \n",
    "cost_history = []\n",
    "for epoch in range(training_epochs+1):\n",
    "\n",
    "    sess.run(optimizer, feed_dict = {X: np.asarray(train_input).reshape(20,95000), \n",
    "                                     Y: np.asarray(train_output).reshape(21,95000), learning_rate: .1})\n",
    "    cost_ = sess.run(cost, feed_dict={ X:np.asarray(train_input).reshape(20,95000), \n",
    "                                      Y: np.asarray(train_output).reshape(21,95000), learning_rate: .1})\n",
    "    cost_history = np.append(cost_history, cost_)\n",
    "    \n",
    "    if (epoch % 10 == 0):\n",
    "        print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "        incorrect = sess.run(error,{X: np.asarray(test_input).reshape(20,test_size), \n",
    "                                    Y: np.asarray(test_output).reshape(21,test_size)})\n",
    "        print(100 * incorrect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Zalando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('fashion-mnist_train.csv', header = 0)\n",
    "data_test = pd.read_csv('fashion-mnist_test.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_train['label'].values.reshape(1, 60000)\n",
    "\n",
    "labels_ = np.zeros((60000, 10))\n",
    "labels_[np.arange(60000), labels] = 1\n",
    "train = data_train.drop('label', axis=1)\n",
    "\n",
    "labels_dev = data_test['label'].values.reshape(1, 10000)\n",
    "\n",
    "labels_dev_ = np.zeros((10000, 10))\n",
    "labels_dev_[np.arange(10000), labels_dev] = 1\n",
    "dev = data_test.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(labels_.shape)\n",
    "print(labels_dev_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train / 255.0)\n",
    "dev = np.array(dev / 255.0)\n",
    "labels_ = np.array(labels_)\n",
    "labels_test_ = np.array(labels_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='X')\n",
    "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "        # Shape of the filter-weights for the convolution\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "    layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "    layer += biases\n",
    "        \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "        # TensorFlow operation for convolution\n",
    "    layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "         # Create new weights and biases.\n",
    "    weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=1, filter_size=5, num_filters=6)\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1)\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1)\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=16)\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2)\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2)\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu2, [-1, num_features])\n",
    "\n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_relu3, num_inputs=128, num_outputs=10, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for Zalando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        train_accuracy = 0\n",
    "        for i in range(0, train.shape[0], batch_size):\n",
    "            x_batch = train[i:i + batch_size,:]\n",
    "            y_true_batch = labels_[i:i + batch_size,:]\n",
    "            \n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            sess.run(optimizer, feed_dict={x: x_batch, y_true: y_true_batch})\n",
    "            train_accuracy += sess.run(accuracy, feed_dict={x: x_batch, y_true: y_true_batch})\n",
    "        \n",
    "        train_accuracy /= int(len(labels_)/batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        vali_accuracy = sess.run(accuracy, feed_dict={x:dev, y_true:labels_dev_})\n",
    "\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 1 completed : Time usage 80 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6370500011431675\n",
      "\t- Validation Accuracy:\t0.7505000233650208\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 2 completed : Time usage 82 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.761499999264876\n",
      "\t- Validation Accuracy:\t0.7827000021934509\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 3 completed : Time usage 85 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.7906666641434034\n",
      "\t- Validation Accuracy:\t0.8055999875068665\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 4 completed : Time usage 84 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8107499983906746\n",
      "\t- Validation Accuracy:\t0.8183000087738037\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 5 completed : Time usage 77 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8250666657090187\n",
      "\t- Validation Accuracy:\t0.8307999968528748\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 6 completed : Time usage 71 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8363333313663801\n",
      "\t- Validation Accuracy:\t0.8391000032424927\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 7 completed : Time usage 71 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8451833318670591\n",
      "\t- Validation Accuracy:\t0.8474000096321106\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 8 completed : Time usage 71 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8511499991019567\n",
      "\t- Validation Accuracy:\t0.8528000116348267\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 9 completed : Time usage 73 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.855983331600825\n",
      "\t- Validation Accuracy:\t0.8553000092506409\n",
      "--> 0\n",
      "--> 5000\n",
      "--> 10000\n",
      "--> 15000\n",
      "--> 20000\n",
      "--> 25000\n",
      "--> 30000\n",
      "--> 35000\n",
      "--> 40000\n",
      "--> 45000\n",
      "--> 50000\n",
      "--> 55000\n",
      "Epoch 10 completed : Time usage 76 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8595833310484886\n",
      "\t- Validation Accuracy:\t0.8568999767303467\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        #for batch in range(0, int(len(labels_)/batch_size)):\n",
    "            \n",
    "        for i in range(0, train.shape[0], batch_size):\n",
    "            if (i%5000 == 0):\n",
    "                print('-->',i)\n",
    "            x_batch = train[i:i + batch_size,:]\n",
    "            y_true_batch = labels_[i:i + batch_size,:]\n",
    "            \n",
    "            # Get a batch of images and labels\n",
    "            #x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            #summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            #writer.add_summary(summ, epoch*int(len(labels_)/batch_size) + batch)\n",
    "        \n",
    "          \n",
    "        train_accuracy /= int(len(labels_)/batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:dev, y_true:labels_dev_})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [0.6370500011431675, 0.761499999264876, 0.7906666641434034, 0.8107499983906746, 0.8250666657090187, 0.8363333313663801,\n",
    "       0.8451833318670591, 0.8511499991019567, 0.855983331600825, 0.8595833310484886]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25fc540fef0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAHSxJREFUeJzt3Xt0nHd95/H3x5IlWbJsSZYSX2TJSuLEThxyGxyId5twSXBYStLQpU62bGjZelkI7bK0u0nLAWpOT9lzKIU9Jw0YMJduIcuyLPX2hJiUJJBCApZzAV/ixNdYthXLlmLL8kUXf/ePeWyPZdka25JHmufzOkdH8/ye3zP6amJ95pvfPM+MIgIzM0uHCYUuwMzMLh6HvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpciwoS9phaQ9ktaeYb8k/Q9JmyT9WtKNOfvul/Rq8nX/SBZuZmbnLp9O/5vA4rPsvxOYm3wtBR4BkFQHfBq4GVgIfFpS7YUUa2ZmF2bY0I+InwGdZ5lyF/DtyHoOqJE0A3gX8EREdEZEF/AEZ3/yMDOzUVY6AvcxC9iRs92WjJ1p/DSSlpL9vwSqqqpumjdv3giUZWaWHmvWrNkbEQ3DzRuJ0NcQY3GW8dMHI5YDywEymUy0traOQFlmZukhaXs+80bi7J02YHbOdiOw6yzjZmZWICMR+iuBf5+cxfMWYH9E7AZWAXdIqk1ewL0jGTMzswIZdnlH0neB24B6SW1kz8iZCBARXwYeA94NbAIOAX+Q7OuU9FlgdXJXyyLibC8Im5nZKBs29CPi3mH2B/DRM+xbAaw4v9LMzGyk+YpcM7MUceibmaWIQ9/MLEUc+mZmKeLQNzNLEYe+mVmKOPTNzFLEoW9mliIOfTOzFHHom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpUheoS9psaSNkjZJenCI/c2SfiLp15KeltSYs29A0ovJ18qRLN7MzM5NPh+MXgI8DNwOtAGrJa2MiPU50z4PfDsiviXp7cBfAx9I9h2OiOtHuG4zMzsP+XT6C4FNEbElInqBR4G7Bs25GvhJcvupIfabmdkYkE/ozwJ25Gy3JWO5XgLel9z+HaBa0rRku0JSq6TnJN19QdWamdkFySf0NcRYDNr+U+BWSS8AtwI7gf5kX1NEZID7gC9Kuvy0HyAtTZ4YWjs6OvKv3szMzkk+od8GzM7ZbgR25U6IiF0RcU9E3AD8RTK2//i+5PsW4GnghsE/ICKWR0QmIjINDQ3n83uYmVke8gn91cBcSS2SyoAlwCln4Uiql3T8vh4CViTjtZLKj88BFgG5LwCbmdlFNGzoR0Q/8ACwCtgAfC8i1klaJum9ybTbgI2SXgEuBf4qGZ8PtEp6iewLvJ8bdNaPmZldRIoYvDxfWJlMJlpbWwtdhpnZuCJpTfL66Vn5ilwzsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIg59M7MUceibmaWIQ9/MLEUc+mZmKeLQNzNLEYe+mVmKOPTNzFLEoW9mliIOfTOzFHHom5mliEPfzCxF8gp9SYslbZS0SdKDQ+xvlvQTSb+W9LSkxpx990t6Nfm6fySLNzOzczNs6EsqAR4G7gSuBu6VdPWgaZ8Hvh0RbwKWAX+dHFsHfBq4GVgIfFpS7ciVb2Zm5yKfTn8hsCkitkREL/AocNegOVcDP0luP5Wz/13AExHRGRFdwBPA4gsv28zMzkc+oT8L2JGz3ZaM5XoJeF9y+3eAaknT8jwWSUsltUpq7ejoyLd2MzM7R/mEvoYYi0HbfwrcKukF4FZgJ9Cf57FExPKIyEREpqGhIY+SzMzsfJTmMacNmJ2z3Qjsyp0QEbuAewAkTQbeFxH7JbUBtw069ukLqNfMzC5APp3+amCupBZJZcASYGXuBEn1ko7f10PAiuT2KuAOSbXJC7h3JGNmZlYAw4Z+RPQDD5AN6w3A9yJinaRlkt6bTLsN2CjpFeBS4K+SYzuBz5J94lgNLEvGzMysABRx2hJ7QWUymWhtbS10GWZm44qkNRGRGW6er8g1M0sRh76ZWYo49M3MUsShb2aWIg59M7MUceibmaWIQ9/MLEUc+mZmKeLQNzNLEYe+mVmKOPTNzFLEoW9mliIOfTOzFHHom5mliEPfzKzAIoIjfQPsP9w36j8rn49LNDOzM4gIenoH6D7Sx8Ej/Rw40k/3kT66j/TTfaSfg0dP3j5wYryPg0f7T4x3H+mjbyC4samGH3xk0ajW69A3s9Q6HthdPb1JQOcGdl8S4KcGd26gHw/vY8N8FtUEweTyUqorJlJdUUp1RSmXVFdweUNpsj2RyeWlzK6rHPXf2aFvZkUhIjjcN0BnTy9dPX10Heql61Bvst1L56HseGfPyfE3DvXRO3DsrPc7sUSnhHV1+URm11VSXVHKlJzxyeU5cyomMuV4mFeUUlVWgqSL9EicXV6hL2kx8CWgBPhaRHxu0P4m4FtATTLnwYh4TNIcsp+ruzGZ+lxEfHhkSjezYnakbyAntPuS0D4e1r10Huo7sX183tH+oQNcgtrKMmorJ1JXVUZTXSXXNdZQW1VGXdVEaiaVnQjr3OCuriilvHTCmAnskTBs6EsqAR4GbgfagNWSVkbE+pxpnyT7gemPSLoaeAyYk+zbHBHXj2zZZjbe9A0cY+/Bo3R0H2XPgaN0JLcHd97Htw/1DpzxvqZOyoZ3beVEZtZUcM3MKdRVlVFTmQ3x2sqy7P6qMuoqy5gyaSIlE4onuC9EPp3+QmBTRGwBkPQocBeQG/oBTEluTwV2jWSRZjY2RQQHj/Zng7z76KDvR+jIGevs6R3yPqrLS6lNArp+chlzL51MXWUS2Emw54Z4zaSJlJb4xMPzlU/ozwJ25Gy3ATcPmvMZ4MeSPgZUAe/M2dci6QXgAPDJiHhm8A+QtBRYCtDU1JR38WY2OgaOBft6cjry5PueA0eS7yfD/XDf6R35xBJxSXUF9dXlzK6r5MbmWi6pLqehupxLqiuS7+VMm1xGeWlJAX7D9Mon9If6f6LBr1XfC3wzIv5G0luBv5e0ANgNNEXEPkk3AT+UdE1EHDjlziKWA8sBMpnMMK+Dm9n5igj2Huzltc4eXj9wakee26nvO3h0yDNSplSUngju62fXnAzyKeU0TK5IvpdTUzmxqNbBi0k+od8GzM7ZbuT05ZsPAYsBIuJZSRVAfUTsAY4m42skbQauBFovtHAzG1pE0HHwKNv3HWLr3h627+th275DbNvbw/Z9hzh4tP+U+SUTRP3kMi6pruDSKRVcO2vqiU68Iacrb6gup2Kiu/LxLp/QXw3MldQC7ASWAPcNmvMa8A7gm5LmAxVAh6QGoDMiBiRdBswFtoxY9WYpFRF0dB89Eebb9vWcEvI9OS+Clk4Qs+sqaZ5WyZvn1DFnWiXN06qYPjUb6HWVZUzwi5ypMWzoR0S/pAeAVWRPx1wREeskLQNaI2Il8Angq5I+Tnbp54MREZJ+C1gmqR8YAD4cEZ2j9tuYFZGIYE/30ROhvm3fIbbv62Hr3uz3Q4OCvSkJ9oUtdbTUV9E8rZKW+ipm1kxiol/4tIQixtYSeiaTidZWr/5YOkQErx84mg31vbnBnu3cc18knViS7djnTDsZ6M3TqmiZVsXMmgqf0ZJyktZERGa4eb4i1+wiONw7wCuvd/Ny+wG27O1h+95DSffew5G+kxcUHQ/2lmlV3HJ5PS312aWYlvoqZkx1sNuFc+ibjaCIYOcbh3l5dzbgN+zuZkP7Abbt7TlxNkxZyQRm102ipb6KRVfUM6e+ijnTsh38zJpJvojIRpVD3+w8HertZ2N7Ny+3d7Nh9wFeTgK++8jJs2Oa6iqZP6Oa337TTObPqGbe9CnMrqt0sFvBOPTNhhERtHUdZsPubOf+cvsBXm7vZtu+Ho6/JDa5vJR506u56/qZzJs+hfkzpnDV9Goml/tPzMYW/4s0y3HwaLZ737D7QDbcd2c7+ePntkswZ1oV86ZXc/f1s5g/o5r5M6Ywq2aST3u0ccGhb6l07Fiwo+tQds39eMC3d7N936ETc6orSpk/fQr33DiL+TOmMG96NVdeWk2Vu3cbx/yv14peb/8x1u3az9qd+9nQ3s3Luw+wsb37xAVMErTUV7Fg5lR+98bGbMDPqGZWzSS/lYAVHYe+FZ2unl6ef62L1u1drNnWxUttb5x4n/UpFaXMnzGFf5uZfeKF1SsvrWZSmd9ewNLBoW/jWkSwdW/PiYBv3d7J5o4eIHuV6jWzpvL7b2km01zLdbNrmDG1wt27pZpD38aVo/0DrN25n9Zt2U7++e1d7Evep33qpInc1FzLPTc2clNzLdc11riDNxvEoW9j2r6DR1mzvevE16937qc3WaqZM62S2666hMycWjLNtVzeMNln0JgNw6FvY0ZEsLmjhzXbO2ndlg35LXuzSzUTS8SCWVO5/63N3NRcx03NtTRUlxe4YrPxx6FvBXOkb4Bft+1PuvhO1mzvoutQHwC1ldmlmt/NNJJpruNNjVP9Xu5mI8ChbxfN3oNHkw6+k9btXazduZ++gewlrZfVV/HO+ZeSmVPLTc11XN5Q5RdczUaBQ99GzYEjfTy5YQ/PvLqXNds72ZZc+FRWMoFrG6fyh4tauKm5lpuaa5k22Us1ZheDQ99GVGdPL0+sb+dHa9v5+aa99A1EslRTx5KFTWSaa1kwy0s1ZoXi0LcL9vqBI6xa186PftPOL7fu41hAY+0kPnjLHBYvmM4Ns2t9Vo3ZGOHQt/Oyo/MQj69t50drd/P8a28AcHlDFR+57QoWL5jONTOneE3ebAzKK/QlLQa+RPYzcr8WEZ8btL8J+BZQk8x5MCIeS/Y9BHyI7Gfk/nFErBq58u1i2rSnOwn6dtbtOgDA1TOm8Inbr+TOa6dzxSXVBa7QzIYzbOhLKgEeBm4H2oDVklZGxPqcaZ8EvhcRj0i6GngMmJPcXgJcA8wE/lnSlRExgI15EcG6XQeySzdr29m05yAANzTV8Ofvnsfia2bQNK2ywFWa2bnIp9NfCGyKiC0Akh4F7gJyQz+AKcntqcCu5PZdwKMRcRTYKmlTcn/PjkDtNgqOHQtebHuDx9e28/jadl7rPMQEwc0t0/jAW5p51zXTmT61otBlmtl5yif0ZwE7crbbgJsHzfkM8GNJHwOqgHfmHPvcoGNnDf4BkpYCSwGampryqdtGUP/AMVZv6+LxtbtZte512g8cYWKJWHRFPR+57XJuv/pSn1JpViTyCf2hXo2LQdv3At+MiL+R9Fbg7yUtyPNYImI5sBwgk8mctt9GXm//MX6xeS+Pr23nx+tfp7Onl4qJE7j1ygb+24KrePu8S5k6aWKhyzSzEZZP6LcBs3O2Gzm5fHPch4DFABHxrKQKoD7PY+0iOdw7wE9f6WDVunb+ecPrdB/pZ3J5KW+fdwl3LpjOrVc1UFnmE7rMilk+f+GrgbmSWoCdZF+YvW/QnNeAdwDflDQfqAA6gJXAdyR9gewLuXOBX41Q7ZaH7iN9PPnyHlata+eplzs43DdATeVEFl8znTuvnc4tl9f7QimzFBk29COiX9IDwCqyp2OuiIh1kpYBrRGxEvgE8FVJHye7fPPBiAhgnaTvkX3Rtx/4qM/cGX3HjgVPvryH7/7qNZ55dS+9A8doqC7nfTfN4s4FM7i5pY7SkgmFLtPMCkDZbB47MplMtLa2FrqMcalv4Bj/76VdfPmnm3nl9YPMmFrBu6+dwZ0LpnNjk6+KNStmktZERGa4eV7ALQKHewf4X6tf46vPbGXnG4e56tJqvvh71/OeN81wR29mp3Doj2NvHOrl289u55u/2EZnTy9vnlPLZ+++hrdddYnfAsHMhuTQH4d27z/M15/Zynd+9RqHegd4x7xL+PBtl/PmOXWFLs3MxjiH/jiyac9Blv9sM//3hZ0cC3jvdTP5j7dexrzpU4Y/2MwMh/648NKON3jk6c2sWt9OWckE7lvYxH/415cxu87ve2Nm58ahP0ZFBP+yaS+PPL2ZX2zex5SKUh542xXcf8sc6v2WCGZ2nhz6Y8zAseDxte088tNNrN15gEunlPMX757PvTc3Mbnc/7nM7MI4RcaIo/0D/OD5nXzlp5vZtu8QLfVV/Pf3XcvdN8yivNRXzJrZyHDoF1j3kT6+88vX+Pq/bGVP91GunTWVR/7djdxxzXRKfDGVmY0wh36B7D14lG/8fCvffnY73Uf6WXTFNL7w/utZdMU0n2NvZqPGoX+R7eg8xPKfbeF7rTvoHTjG4mum8+FbL+e62TWFLs3MUsChf5Fs2H2AL/90M//0691MENxzQyNLb72MyxsmF7o0M0sRh/4o+9XWTh55ehNPbeygqqyEP1w0hw/9q8v8kYNmVhAO/VFw7Fjw1MY9PPL0Zlq3d1FXVcYnbr+SD7y1mZrKskKXZ2Yp5tAfYe37j/DBb/yKl9u7mVUzib987zW8PzObSWU+7dLMCs+hP8K+9JNX2dLRwxfefx2/fd1MJvqtjc1sDHHoj6C2rkP879Yd3HdzE/fc2FjocszMTuM2dAQ9/NRmJkj8p9suL3QpZmZDyiv0JS2WtFHSJkkPDrH/byW9mHy9IumNnH0DOftWjmTxY8nxLn/JwtnMmDqp0OWYmQ1p2OUdSSXAw8DtQBuwWtLKiFh/fE5EfDxn/seAG3Lu4nBEXD9yJY9N7vLNbDzIp9NfCGyKiC0R0Qs8Ctx1lvn3At8dieLGC3f5ZjZe5BP6s4AdOdttydhpJDUDLcCTOcMVklolPSfp7jMctzSZ09rR0ZFn6WOHu3wzGy/yCf2h3v0rzjB3CfD9iBjIGWuKiAxwH/BFSaclY0Qsj4hMRGQaGhryKGnscJdvZuNJPqHfBszO2W4Edp1h7hIGLe1ExK7k+xbgaU5d7x/33OWb2XiST+ivBuZKapFURjbYTzsLR9JVQC3wbM5YraTy5HY9sAhYP/jY8cpdvpmNN8OevRMR/ZIeAFYBJcCKiFgnaRnQGhHHnwDuBR6NiNyln/nAVyQdI/sE87ncs37GO3f5Zjbe5HVFbkQ8Bjw2aOxTg7Y/M8RxvwCuvYD6xqzcq2/d5ZvZeOErcs+Tu3wzG48c+ufBa/lmNl459M+Du3wzG68c+ufIXb6ZjWcO/XPkLt/MxjOH/jlwl29m451D/xy4yzez8c6hnyd3+WZWDBz6eXKXb2bFwKGfB3f5ZlYsHPp5cJdvZsXCoT8Md/lmVkwc+sNwl29mxcShfxbu8s2s2Dj0z8JdvpkVG4f+GbjLN7Ni5NA/A3f5ZlaMHPpDcJdvZsUqr9CXtFjSRkmbJD04xP6/lfRi8vWKpDdy9t0v6dXk6/6RLH60uMs3s2I17GfkSioBHgZuB9qA1ZJW5n7AeUR8PGf+x4Abktt1wKeBDBDAmuTYrhH9LUaQP/vWzIpZPp3+QmBTRGyJiF7gUeCus8y/F/hucvtdwBMR0ZkE/RPA4gspeLS5yzezYpZP6M8CduRstyVjp5HUDLQAT57LsZKWSmqV1NrR0ZFP3aPCa/lmVuzyCX0NMRZnmLsE+H5EDJzLsRGxPCIyEZFpaGjIo6TR4S7fzIpdPqHfBszO2W4Edp1h7hJOLu2c67EFdbzL/703u8s3s+KVT+ivBuZKapFURjbYVw6eJOkqoBZ4Nmd4FXCHpFpJtcAdydiY4y7fzNJg2LN3IqJf0gNkw7oEWBER6yQtA1oj4vgTwL3AoxEROcd2Svos2ScOgGUR0Tmyv8KFO97l37uwiZk17vLNrHgNG/oAEfEY8NigsU8N2v7MGY5dAaw4z/ouCnf5ZpYWqb8iN3ct312+mRW71Ie+u3wzS5NUh767fDNLm1SHvrt8M0ub1Ia+u3wzS6PUhr67fDNLo1SGvrt8M0urVIb+3z3tLt/M0il1oe8u38zSLHWh/3dPb0a4yzezdEpV6LvLN7O0S1Xou8s3s7RLTei7yzczS1Hou8s3M0tJ6LvLNzPLSkXou8s3M8sq+tB3l29mdlLRh767fDOzk/IKfUmLJW2UtEnSg2eY835J6yWtk/SdnPEBSS8mX6d9oPpocpdvZnaqYT8jV1IJ8DBwO9AGrJa0MiLW58yZCzwELIqILkmX5NzF4Yi4foTrzou7fDOzU+XT6S8ENkXElojoBR4F7ho054+AhyOiCyAi9oxsmefOXb6Z2enyCf1ZwI6c7bZkLNeVwJWSfi7pOUmLc/ZVSGpNxu++wHrz5i7fzOx0wy7vABpiLIa4n7nAbUAj8IykBRHxBtAUEbskXQY8Kek3EbH5lB8gLQWWAjQ1NZ3jr3C6413+kjc3ucs3M8uRT6ffBszO2W4Edg0x5x8joi8itgIbyT4JEBG7ku9bgKeBGwb/gIhYHhGZiMg0NDSc8y8xmLt8M7Oh5RP6q4G5kloklQFLgMFn4fwQeBuApHqyyz1bJNVKKs8ZXwSsZxR5Ld/M7MyGXd6JiH5JDwCrgBJgRUSsk7QMaI2Ilcm+OyStBwaAP4uIfZJuAb4i6RjZJ5jP5Z71Mxrc5ZuZnVk+a/pExGPAY4PGPpVzO4D/knzlzvkFcO2Fl5kfr+WbmZ1dUV2R6y7fzOzsiib0vZZvZja8vJZ3xoOG6nI+9Z6recf8SwtdipnZmFU0oV9eWsIH3jqn0GWYmY1pRbO8Y2Zmw3Pom5mliEPfzCxFHPpmZini0DczSxGHvplZijj0zcxSxKFvZpYiDn0zsxRx6JuZpYhD38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUiSv0Je0WNJGSZskPXiGOe+XtF7SOknfyRm/X9Krydf9I1W4mZmdu2E/REVSCfAwcDvQBqyWtDIi1ufMmQs8BCyKiC5JlyTjdcCngQwQwJrk2K6R/1XMzGw4+XT6C4FNEbElInqBR4G7Bs35I+Dh42EeEXuS8XcBT0REZ7LvCWDxyJRuZmbnKp+PS5wF7MjZbgNuHjTnSgBJPwdKgM9ExONnOHbW4B8gaSmwNNk8KGljXtUPrR7YewHHFxM/Fqfy43EqPx4nFcNj0ZzPpHxCX0OMxRD3Mxe4DWgEnpG0IM9jiYjlwPI8ahmWpNaIyIzEfY13fixO5cfjVH48TkrTY5HP8k4bMDtnuxHYNcScf4yIvojYCmwk+ySQz7FmZnaR5BP6q4G5kloklQFLgJWD5vwQeBuApHqyyz1bgFXAHZJqJdUCdyRjZmZWAMMu70REv6QHyIZ1CbAiItZJWga0RsRKTob7emAA+LOI2Acg6bNknzgAlkVE52j8IjlGZJmoSPixOJUfj1P58TgpNY+FIk5bYjczsyLlK3LNzFLEoW9mliJFE/r5vFVEWkiaLekpSRuSt8X4k0LXVGiSSiS9IOmfCl1LoUmqkfR9SS8n/0beWuiaCknSx5O/k7WSviupotA1jaaiCP2ct4q4E7gauFfS1YWtqqD6gU9ExHzgLcBHU/54APwJsKHQRYwRXwIej4h5wHWk+HGRNAv4YyATEQvInqyypLBVja6iCH3ye6uI1IiI3RHxfHK7m+wf9WlXQqeFpEbg3wBfK3QthSZpCvBbwNcBIqI3It4obFUFVwpMklQKVFLk1xIVS+jn9XYPaSRpDnAD8MvCVlJQXwT+K3Cs0IWMAZcBHcA3kuWur0mqKnRRhRIRO4HPA68Bu4H9EfHjwlY1uool9PN6u4e0kTQZ+D/Af46IA4WupxAkvQfYExFrCl3LGFEK3Ag8EhE3AD1Aal8DSy4avQtoAWYCVZJ+v7BVja5iCX2/3cMgkiaSDfx/iIgfFLqeAloEvFfSNrLLfm+X9D8LW1JBtQFtEXH8//y+T/ZJIK3eCWyNiI6I6AN+ANxS4JpGVbGEfj5vFZEakkR2zXZDRHyh0PUUUkQ8FBGNETGH7L+LJyOiqDu5s4mIdmCHpKuSoXcA689ySLF7DXiLpMrk7+YdFPkL2/m8y+aYd6a3iihwWYW0CPgA8BtJLyZjfx4RjxWwJhs7Pgb8Q9IgbQH+oMD1FExE/FLS94HnyZ719gJF/pYMfhsGM7MUKZblHTMzy4ND38wsRRz6ZmYp4tA3M0sRh76ZWYo49M3MUsShb2aWIv8fKmngFciTySwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25fc50e60b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(0.6,1)\n",
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed : Time usage 72 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.7134545448557897\n",
      "\t- Validation Accuracy:\t0.879800021648407\n",
      "Epoch 2 completed : Time usage 83 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8977454559369521\n",
      "\t- Validation Accuracy:\t0.9132000207901001\n",
      "Epoch 3 completed : Time usage 85 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.918927274834026\n",
      "\t- Validation Accuracy:\t0.9330000281333923\n",
      "Epoch 4 completed : Time usage 88 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9315272748470307\n",
      "\t- Validation Accuracy:\t0.9441999793052673\n",
      "Epoch 5 completed : Time usage 92 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9427454558285799\n",
      "\t- Validation Accuracy:\t0.9535999894142151\n",
      "Epoch 6 completed : Time usage 106 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9518909122727134\n",
      "\t- Validation Accuracy:\t0.9606000185012817\n",
      "Epoch 7 completed : Time usage 126 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9583272760564631\n",
      "\t- Validation Accuracy:\t0.9657999873161316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-139317f50dca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# Run the optimizer using this batch of training data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# Calculate the accuracy on the batch of training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        for batch in range(0, int(len(data.train.labels)/batch_size)):\n",
    "            \n",
    "            # Get a batch of images and labels\n",
    "            x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(len(data.train.labels)/batch_size) + batch)\n",
    "        \n",
    "          \n",
    "        train_accuracy /= int(len(data.train.labels)/batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:data.validation.images, y_true:data.validation.labels})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
