{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Deep Learning - a use case based approach to understand deep neural networks\n",
    "\n",
    "### Umberto Michelucci\n",
    "\n",
    "Buy the book: https://www.apress.com/us/book/9781484237892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Umberto Michelucci 2018-2019 - umberto.michelucci@gmail.com \n",
    "\n",
    "github repository: https://github.com/Apress/applied-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000',\n",
       " '0001',\n",
       " '0010',\n",
       " '0011',\n",
       " '0100',\n",
       " '0101',\n",
       " '0110',\n",
       " '0111',\n",
       " '1000',\n",
       " '1001',\n",
       " '1010',\n",
       " '1011',\n",
       " '1100',\n",
       " '1101',\n",
       " '1110',\n",
       " '1111']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ['{0:04b}'.format(i) for i in range(2**4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 15\n",
    "ll = 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = ['{0:015b}'.format(i) for i in range(ll)]\n",
    "shuffle(train_input)\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append([j])\n",
    "    ti.append(np.array(temp_list))\n",
    "train_input = ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 15, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       ..., \n",
       "       [0, 1, 0, ..., 1, 0, 1],\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).reshape(ll,nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = []\n",
    " \n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*(nn+1))\n",
    "    temp_list[count]=1\n",
    "    train_output.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 16)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = ll-2000\n",
    "test_input = train_input[NUM_EXAMPLES:]\n",
    "test_output = train_output[NUM_EXAMPLES:] #everything beyond 10,000\n",
    " \n",
    "train_input = train_input[:NUM_EXAMPLES]\n",
    "train_output = train_output[:NUM_EXAMPLES] #till 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 15, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30768, 15, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, nn,1])\n",
    "target = tf.placeholder(tf.float32, [None, (nn+1)])\n",
    "\n",
    "num_hidden = 24\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden,state_is_tuple=True)\n",
    "\n",
    "val, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\n",
    "val = tf.transpose(val, [1, 0, 2])\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(target * tf.log(tf.clip_by_value(prediction,1e-10,1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umber\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30768"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  0\n",
      "Epoch  1 error 43.4%\n",
      "Epoch -  10\n",
      "Epoch 11 error 14.6%\n",
      "Epoch -  20\n",
      "Epoch 21 error 5.4%\n",
      "Epoch -  30\n",
      "Epoch 31 error 3.6%\n",
      "Epoch -  40\n",
      "Epoch 41 error 2.3%\n",
      "Epoch -  50\n",
      "Epoch 51 error 1.4%\n",
      "Epoch -  60\n",
      "Epoch 61 error 1.2%\n",
      "Epoch -  70\n",
      "Epoch 71 error 1.0%\n",
      "Epoch -  80\n",
      "Epoch 81 error 0.7%\n",
      "Epoch -  90\n",
      "Epoch 91 error 0.7%\n",
      "Epoch 100 error 0.6%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "no_of_batches = int(len(train_input)/batch_size)\n",
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "        ptr+=batch_size\n",
    "        sess.run(minimize,{data: inp, target: out})\n",
    "    if (i % 10 == 0):\n",
    "        print (\"Epoch - \",str(i))\n",
    "        incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "        print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-f1db5c93e2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print (sess.run(model.prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0],[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 20\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Number of neurons in the layers\n",
    "n1 = 15 # Number of neurons in layer 1\n",
    "n2 = 21 # Number of neurons in output layer \n",
    "\n",
    "cost_history = np.empty(shape=[1], dtype = float)\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "X = tf.placeholder(tf.float32, [20, None])\n",
    "Y = tf.placeholder(tf.float32, [21, None])\n",
    "W1 = tf.Variable(tf.truncated_normal([n1, n_dim], stddev=.1)) \n",
    "b1 = tf.Variable(tf.constant(0.1, shape = [n1,1]) )\n",
    "W2 = tf.Variable(tf.truncated_normal([n2, n1], stddev=.1)) \n",
    "b2 = tf.Variable(tf.constant(0.1, shape = [n2,1])) \n",
    "                 \n",
    "# Let's build our network...\n",
    "Z1 = tf.nn.relu(tf.matmul(W1, X) + b1) # n1 x n_dim * n_dim x n_obs = n1 x n_obs\n",
    "Z2 = tf.matmul(W2, Z1) + b2 # n2 x n1 * n1 * n_obs = n2 x n_obs\n",
    "y_ = tf.nn.softmax(Z2,0) # n2 x n_obs (10 x None)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(y_)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "mistakes = tf.not_equal(tf.argmax(Y, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.191768\n",
      "100.0\n",
      "Reached epoch 10 cost J = 0.191765\n",
      "100.0\n",
      "Reached epoch 20 cost J = 0.191763\n",
      "100.0\n",
      "Reached epoch 30 cost J = 0.19176\n",
      "100.0\n",
      "Reached epoch 40 cost J = 0.191761\n",
      "100.0\n",
      "Reached epoch 50 cost J = 0.191758\n",
      "100.0\n",
      "Reached epoch 60 cost J = 0.191755\n",
      "100.0\n",
      "Reached epoch 70 cost J = 0.191755\n",
      "100.0\n",
      "Reached epoch 80 cost J = 0.191752\n",
      "100.0\n",
      "Reached epoch 90 cost J = 0.191751\n",
      "100.0\n",
      "Reached epoch 100 cost J = 0.191748\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "train_size = 95000\n",
    "test_size = 5000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 100\n",
    "    \n",
    "cost_history = []\n",
    "for epoch in range(training_epochs+1):\n",
    "\n",
    "    sess.run(optimizer, feed_dict = {X: np.asarray(train_input).reshape(20,95000), \n",
    "                                     Y: np.asarray(train_output).reshape(21,95000), learning_rate: .1})\n",
    "    cost_ = sess.run(cost, feed_dict={ X:np.asarray(train_input).reshape(20,95000), \n",
    "                                      Y: np.asarray(train_output).reshape(21,95000), learning_rate: .1})\n",
    "    cost_history = np.append(cost_history, cost_)\n",
    "    \n",
    "    if (epoch % 10 == 0):\n",
    "        print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "        incorrect = sess.run(error,{X: np.asarray(test_input).reshape(20,test_size), \n",
    "                                    Y: np.asarray(test_output).reshape(21,test_size)})\n",
    "        print(100 * incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_input).reshape(20,95000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(train_input).reshape(95000,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
